{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plangym import AtariEnvironment, ParallelEnvironment\n",
    "from plangym.montezuma import Montezuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = AtariEnvironment(name=\"MsPacman-v0\", clone_seeds=True, autoreset=True)\n",
    "state, obs = env.reset()\n",
    "env = Montezuma(autoreset=True)\n",
    "state, obs = env.reset()\n",
    "states = [state.copy() for _ in range(10)]\n",
    "actions = [env.action_space.sample() for _ in range(10)]\n",
    "\n",
    "new_States, observs, rewards, ends, infos = env.step_batch(states=states, actions=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([247, 60, 6, ..., 1.0, 159.4, 29.0], dtype=object),\n",
       " array([  0. ,   0. ,   1. , 159.4,  29. ,   1. ,   0. ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False},\n",
       " {'ale.lives': 3,\n",
       "  'lives': 3,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ParallelEnvironment(env_class=AtariEnvironment, name=\"MsPacman-v0\",\n",
    "                          clone_seeds=True, autoreset=True, blocking=False)\n",
    "\n",
    "state, obs = env.reset()\n",
    "\n",
    "states = [state.copy() for _ in range(10)]\n",
    "actions = [env.action_space.sample() for _ in range(10)]\n",
    "\n",
    "new_States, observs, rewards, ends, infos = env.step_batch(states=states, actions=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = Montezuma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mon.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([247, 60, 6, ..., 220, 164, 36], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:1021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1037"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mon.env.unwrapped.clone_full_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([247, 60, 6, ..., 1.0, 159.4, 29.0], dtype=object),\n",
       " array([  0. ,   0. ,   1. , 159.4,  29. ,   1. ,   1. ]),\n",
       " 0.0,\n",
       " False,\n",
       " {'ale.lives': 6,\n",
       "  'lives': 6,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.step(action=0, state=data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0. ,   0. ,   1. , 159.4,  29. ,   1. ,   2. ]),\n",
       " 0.0,\n",
       " False,\n",
       " {'ale.lives': 6,\n",
       "  'lives': 6,\n",
       "  'terminal': False,\n",
       "  'lost_live': False,\n",
       "  'game_end': False})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0. ,   0. ,   1. , 159.4,  29. ,   1. ,   2. ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(p.tuple + mon._env.room_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1, 159.4, 29.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.pos.tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MontezumaPosLevel' object has no attribute 'objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2ba3ab8ea141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MontezumaPosLevel' object has no attribute 'objects'"
     ]
    }
   ],
   "source": [
    "[mon.pos.x, mon.pos.y, mon.pos.objects, mon.pos.level, mon.pos.room]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plangym import AtariEnvironment, ParallelEnvironment\n",
    "from plangym.montezuma import MyMontezuma, MontezumaPosLevel\n",
    "class Montezuma(AtariEnvironment):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_repeat_action: int = 1,\n",
    "        min_dt: int = 1,\n",
    "        episodic_live: bool = False,\n",
    "        autoreset: bool = True,\n",
    "        *args, **kwargs,\n",
    "    ):\n",
    "\n",
    "        super(Montezuma, self).__init__(name=\"MontezumaRevengeDeterministic-v4\",\n",
    "                                        n_repeat_action=n_repeat_action,\n",
    "                                        clone_seeds=True, min_dt=min_dt, obs_ram=False)\n",
    "        self._env = MyMontezuma(*args, **kwargs,)\n",
    "        self.action_space = self._env.action_space\n",
    "        self.observation_space = self._env.observation_space\n",
    "        self.reward_range = self._env.reward_range\n",
    "        self.metadata = self._env.metadata\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        return getattr(self._env, item)\n",
    "\n",
    "    @property\n",
    "    def n_actions(self):\n",
    "        return self._env.action_space.n\n",
    "\n",
    "    def get_state(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Recover the internal state of the simulation. If clone seed is False the\n",
    "        environment will be stochastic.\n",
    "        Cloning the full state ensures the environment is deterministic.\n",
    "        \"\"\"\n",
    "        data = self._env.get_restore()\n",
    "        (\n",
    "            full_state,\n",
    "            score,\n",
    "            steps,\n",
    "            pos,\n",
    "            room_time,\n",
    "            ram_death_state,\n",
    "            score_objects,\n",
    "            cur_lives,\n",
    "        ) = data\n",
    "        metadata = np.array([score, steps, room_time, ram_death_state, score_objects, cur_lives])\n",
    "        array = np.concatenate([full_state, metadata, np.array(pos.tuple)])\n",
    "        return array\n",
    "    \n",
    "    def set_state(self, state: np.ndarray):\n",
    "        \"\"\"\n",
    "        Set the internal state of the simulation.\n",
    "\n",
    "        Args:\n",
    "            state: Target state to be set in the environment.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        pos = MontezumaPosLevel(*state[-5:].tolist())\n",
    "        score, steps, room_time, ram_death_state, score_objects, cur_lives = state[-11:-5].tolist()\n",
    "        full_state = state[:1037].copy().astype(np.uint8)\n",
    "        data = (\n",
    "                full_state,\n",
    "                score,\n",
    "                steps,\n",
    "                pos,\n",
    "                room_time,\n",
    "                ram_death_state,\n",
    "                score_objects,\n",
    "                cur_lives,\n",
    "               )\n",
    "        self._env.restore(data)\n",
    "\n",
    "    def step(\n",
    "        self, action: np.ndarray, state: np.ndarray = None, n_repeat_action: int = None\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "\n",
    "        Take n_repeat_action simulation steps and make the environment evolve\n",
    "        in multiples of min_dt.\n",
    "        The info dictionary will contain a boolean called 'lost_live' that will\n",
    "        be true if a life was lost during the current step.\n",
    "\n",
    "        Args:\n",
    "            action: Chosen action applied to the environment.\n",
    "            state: Set the environment to the given state before stepping it.\n",
    "            n_repeat_action: Consecutive number of times that the action will be applied.\n",
    "\n",
    "        Returns:\n",
    "            if states is None returns (observs, rewards, ends, infos)\n",
    "            else returns(new_states, observs, rewards, ends, infos)\n",
    "        \"\"\"\n",
    "        n_repeat_action = n_repeat_action if n_repeat_action is not None else self.n_repeat_action\n",
    "        if state is not None:\n",
    "            self.set_state(state)\n",
    "        reward = 0\n",
    "        _end, lost_live = False, False\n",
    "        info = {\"lives\": -1}\n",
    "        terminal = False\n",
    "        game_end = False\n",
    "        for _ in range(int(n_repeat_action)):\n",
    "            for _ in range(self.min_dt):\n",
    "                obs, _reward, _end, _info = self._env.step(action)\n",
    "                _info[\"lives\"] = _info.get(\"ale.lives\", -1)\n",
    "                lost_live = info[\"lives\"] > _info[\"lives\"] or lost_live\n",
    "                game_end = game_end or _end\n",
    "                terminal = terminal or game_end\n",
    "                terminal = terminal or lost_live if self.episodic_life else terminal\n",
    "                info = _info.copy()\n",
    "                reward += _reward\n",
    "                if _end:\n",
    "                    break\n",
    "            if _end:\n",
    "                break\n",
    "        # This allows to get the original values even when using an episodic life environment\n",
    "        info[\"terminal\"] = terminal\n",
    "        info[\"lost_live\"] = lost_live\n",
    "        info[\"game_end\"] = game_end\n",
    "        if state is not None:\n",
    "            new_state = self.get_state()\n",
    "            data = new_state, obs, reward, terminal, info\n",
    "        else:\n",
    "            data = obs, reward, terminal, info\n",
    "        if _end and self.autoreset:\n",
    "            self._env.reset()\n",
    "        return data\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Render the environment using OpenGL. This wraps the OpenAI render method.\"\"\"\n",
    "        return self._env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.cur_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.room_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f88ea40cd68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAAD8CAYAAACbxyOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASAklEQVR4nO3dfawc1XnH8e+vvKklpEBMqYNJDJGDBAg5YAhSCcpLQ4yV1qGqqK2qkNiqQcIqkZBaCBWgRJEqNYBAbVAcYQFRAkGhBIRcJ65JS/+oE64b17zFYPNS7Bq7lwBOQsXr0z9mFs9d7947d2fWM2f395FWu3tmdufM9Tx+zpyZPUcRgZml47earoCZzY6D1iwxDlqzxDhozRLjoDVLjIPWLDFDC1pJiyVtk7Rd0tXD2o7ZuNEwrtNKOgR4GvgssBN4FFgeEU/WvjGzMTOsTHsOsD0ino2IN4F7gKVD2pbZWDl0SN97AvBi4f1O4OP9Vpbk27LMppqMiON6LRhW0M5I0ipgVVPbN2u5F/otGFbQ7gJOLLyfl5e9JyLWAGvAmdZsNoZ1TvsosEDSSZIOB5YBDw5pW2ZjZSiZNiLelrQa+BFwCLA2Ip4YxrbMxs1QLvnMuhJuHpt12xwRi3otaKwjysbH5OTklPdz5sxpqCajwbcx2lAVA7YTrN1BbLPjoDVLjIPWLDEOWrPEOGjNEuOgtYPGHVD1cNDaUPW6vONLPtU4aM0S45srbOicWevloE3A1nUXv/f6jCX3zrhO2fX6rTOM77P6uHlslhhn2gS8fuu+WtZpcj2rj3/l00LdTdN+zlhy74zrlllntuuVqaObypX5Vz4pmU32aiILz3Zdq5czrVk79c207ogyS8zAQSvpREk/kfSkpCckXZmX3yBpl6Qt+WNJfdU1syrntG8DV0XEf0o6CtgsaUO+7OaI+Eb16plZt4GDNiJ2A7vz17+S9BTZIOVmNkS1nNNKmg98DPhpXrRa0lZJayUdU8c2zCxTOWglvQ+4D/hyROwDbgM+Aiwky8Q39vncKkkTkiaq1sFsnFS65CPpMOAh4EcRcVOP5fOBhyLi9Bm+x5d8zKaq/5KPJAG3A08VA1bS3MJqFwGPD7oNMztQld7jPwD+AnhM0pa87CvAckkLgQCeBy6rVEMzm8J3RJm1k++IMhsVDlqzxDhozRLjoDVLjIPWLDEOWrPEOGjNEuOgNUuMg9YsMQ5as8Q4aM0S46A1S4yD1iwxDlqzxDhozRLjoDVLjIPWLDGVJ+CS9DzwK+Ad4O2IWCTpWOD7wHyyIWcujohX+n3HUR/+IGdff3nVqpiNjIdXXNd3WV2Z9lMRsbAwPMbVwMaIWABszN+bWQ2G1TxeCtyZv74T+MKQtmM2dioP7CbpOeAVstEXvxURayS9GhFH58sFvNJ53+c7PLCb2VRDnVT6vIjYJen3gA2SflFcGBHRKyglrQJW1bB9s7FSuXkcEbvy573A/cA5wJ7OoOX5894en1sTEYv6/W9iZr1VClpJR+bTXCLpSOACshkFHgQuzVe7FHigynbMbL+qzePjgfuz01YOBb4XEeslPQrcK2kl8AJwccXtVPbSxMoDyn5/0e0N1MRS033sNH3ceIYBs3YaakdUEpxpbVDOtL0q4Uxr1s2Z1pnWBuVM26sSzrRm3ZxpnWltUM60vSrhTGvWzZnWmdYG5UzbqxLOtGbdnGmdaW1QzrS9KuFMa9atb6b1GFFmiXHz2GwGbh73qoSbx2bd3BHlTGuDcqbtVQlnWrNuzrTOtDYoZ9pelXCmNetWf6aVdArZLAIdJwPXAUcDfwn8b17+lYhYN+h26uJMa4MayUwr6RBgF/Bx4EvAryPiG7P4vDNtw7aumzqM1xlL7m2oJpYb+jntZ4AdEfFCPshb6zjT2qDalmnrCtplwN2F96slXQJMAFdNN/nWwdL0H7rtXr91X9NVaK22HTt1TAtyOPA/wGkRsUfS8cAk2TQhXwPmRsSKHp8rzjBwVqVKlOBMO1V3c3g6495UbijT9m0e1xG0S4ErIuKCHsvmAw9FxOkzfIfPaQ+yTYsXl1733PXrh1gT62Oo57TLKTSNJc2NiN3524vIZhxonDPtVMVA3Hnllcy75RZ2Xnnle2XzbrmliWq1UtvOaStl2nwqkP8GTo6I1/Ky7wALyZrHzwOXFYK43/c40zaoGKwdDtrGDa95XIeDEbTOtNPrDlwH7X4jd05bB2faZk13fuvz2cb43mNn2umdu359z+DdtHjx2AfuSJ3T1lYJZ9pGlO1BHvegbYgzrTPt9PplWnOm7V0JZ9pG9QpWZ9fGOdM6006vO9MWX497ADvT9qqEM22jZmoWj3vQNsSZ1pl2ZsXg9Pntfm3LtGMTtE3/odvsd/7q/dmL9T3KusrHUduOnbEJWmdaG5QzbUOa/kO3Ub+f583mZ3vjoG3HjqcFMUuMg9amNe4/gG+jVlzyef/8E+Ls6y9vuhqt8fCK6yp9/tNrv1pTTcpLsc5t9vCK6zxrntmocNCaJSaZ3uOqza9x0v236tX0nM3fs+rnyyjzfS9NrGxdT+4gqp4KlMq0ktZK2ivp8ULZsZI2SHomfz4mL5ekWyVtl7RV0pmVamhmU5RtHt8BdN/XdjWwMSIWABvz9wAXAgvyxyrgturVNLOOUs3jiHgkHw61aCnwyfz1ncC/An+Tl98VWbf0JklHd43QOFTFu1dGoSll1q1KR9TxhUB8CTg+f30C8GJhvZ152RSSVkmakDTx5q9/U6Ea+3XfbvbSxMqety+apayWjqiIiNn+vC4i1gBrILtOW2X73dm102HRKR+VDow6+bpouqpk2j2S5kI2QDmwNy/fBZxYWG9eXjZ0ncAsPjtYbdRUybQPApcCf5c/P1AoXy3pHrKpL187mOezvTKtHajqJR9rTqmglXQ3WafTHEk7gevJgvVeSSuBF4DOT0PWAUuA7cDrZPPVDlUnmxbPYd0hZaOqbO/x8j6LPtNj3QCuqFKpQXVnVwerjSLfxmiWmJEL2u7OKLNRk8y9x1Yvdy6la+QyrdmoG7lM68s85fiST7pGLtP6XNZG3cgFrTOtjbqRC1pnWht1Ixe04MC10TZyHVFWjjuX0jWSmdZslDnTjilf8kmXM61ZYhy0Zolx0JolxkFrlhgHrVliZuw9lrQW+DywNyJOz8v+Hvgj4E1gB/CliHg1Hxv5KWBb/vFNEeHp8FrIPcLpKpNp7+DA2QU2AKdHxBnA08A1hWU7ImJh/nDAmtVsxkzba3aBiPhx4e0m4E/rrZYNm6/TpquOc9oVwD8X3p8k6eeS/k3SJ/p9aBgzDJiNg0p3REm6Fngb+G5etBv4UES8LOks4IeSTouIfd2frXOGAbNxMnCmlfRFsg6qP8+HTSUi3oiIl/PXm8k6qT5aQz3NLDdQ0EpaDPw18McR8Xqh/DhJh+SvTyab7vLZOipqZpkyl3x6zS5wDXAEsEES7L+0cz7wVUlvAe8Cl0fEL4dUd6vAnUvpKtN73Gt2gZ6/Mo+I+4D7qlbKzPrzT/PGlC/5pMu3MZolxkFrlhgHrVlifE47BmZz/jqMz9fFo2xmkgnatnWGNHEg9/ob9KpH93rDqGuZbZSt77C17dipKpmgtfIHfJn1ZnMg9/q+MttoS4YeNQ7ahDSVMercrgO5urEJ2kGzT5sOsjrrUjXTpqRf/Qf99266uT02QTuqyhx4Vf8zOhjbsPIctIk7GOeWPn9tF1+nNUuMg9YsMWPTPG6688DSkMJx4kxrlhgHrVlixqZ5nML1N2teCsfJjJlW0lpJeyU9Xii7QdIuSVvyx5LCsmskbZe0TdLnhlVxs3E16AwDADcXZhJYByDpVGAZcFr+mW92Bnozs3rMGLQR8QhQdnC2pcA9+VCqzwHbgXMq1M/MulQ5p10t6RJgArgqIl4BTiCbJqRjZ152AEmrgFWd9zOdSzR9HmHWFoMG7W3A14DIn28kmx6ktO4ZBs6+frhzdTnorYwUjpOBLvlExJ6IeCci3gW+zf4m8C7gxMKq8/IyM6vJQJlW0tyI2J2/vQjo9Cw/CHxP0k3AB8lmGPhZ5VrWIIWufGteCsfJoDMMfFLSQrLm8fPAZQAR8YSke4EnySbmuiIi3hlO1c3GU60zDOTrfx34epVKmVl/vo3RLDEOWrPEjM29x013HlgaUjhOnGnNEjM2mTaFrnxrXgrHiTOtWWIctGaJcdCaJcZBa5aYsemIarrzwNKQwnHiTGuWmLHJtCl05adkcnJyyvs5c+Y0VJN6pXCcONParExOTh4QsJ1yOzgctFZJJ8OOSqZNgYPWZmXOnDlTAnVycvK9Zzs4HLRmiSkzcsVa4PPA3og4PS/7PnBKvsrRwKsRsVDSfOApYFu+bFNEDHfENjuoOhm1mF27n91UHq4yvcd3AP8A3NUpiIg/67yWdCPwWmH9HRGxsK4K1qXpHr9RM11zuNNkTlEKx0mZ4WYeyTPoASQJuBj4dL3VstQUg9Tnt8NV9TrtJ4A9EfFMoewkST8H9gF/GxH/XnEbtUjh+lsKOsFZzKajFKQpHCdVg3Y5cHfh/W7gQxHxsqSzgB9KOi0i9nV/sDjDwBEf+N2K1bCmjVLgtt3AQSvpUOBPgLM6ZRHxBvBG/nqzpB3AR8mmDpmie4aBQethzXGgNqPKJZ8/BH4RETs7BZKO68ySJ+lkssHKn61WRUtNqp1QqSgzP+3dwH8Ap0jaKWllvmgZU5vGAOcDWyVtAX4AXB4RZWfcs4T0CszijRc2PIMOVk5EfLFH2X3AfdWrZSlwgDZDEc2fTh6MWfPMUvLwius2R8SiXsta8dO8/5s8jCdvnzqN7akrp062172833r91i2zXtnvKlu/QetW975WqVvZdav8O9T9fWW+q+7vq3tfp+N7j80S46A1S0wrmse/PeetGZt0dTdxeq3n5tzg2627CT5Opxv91uvHmdYsMQ5as8T4ko9ZC/mST8n1fA7mSz5t2dfpuHlslhgHrVliWtE89iWftJpzvdb1JR9f8jGzPhy0ZonxJR+zFvIln5Lr+RzMl3zasq/TcfPYLDFlhps5UdJPJD0p6QlJV+blx0raIOmZ/PmYvFySbpW0XdJWSWcOeyfMxkmZTPs2cFVEnAqcC1wh6VTgamBjRCwANubvAS4kG9BtAdkQqbfVXmuzcRYRs3oADwCfJZuvZ25eNhfYlr/+FrC8sP57603zneGHH35MeUz0i5dZndPm04N8DPgpcHxE7M4XvQQcn78+AXix8LGdeZmZ1aB077Gk95GNtPjliNiXTeOTiYiQFLPZcHGGATMrr1SmlXQYWcB+NyL+KS/eI2luvnwusDcv3wWcWPj4vLxsiohYExGL+l2LMrPeyvQeC7gdeCoibiosehC4NH99Kdm5bqf8krwX+VzgtUIz2syqKtHxdB7ZifFWYEv+WAJ8gKzX+BngX4Bj8/UF/COwA3gMWFRiG02f9PvhR9sefTuiWnEb42zPh83GQN/bGH1HlFliHLRmiXHQmiXGQWuWGAetWWJa8XtaYBL4Tf48KuYwOvszSvsCaezPh/staMUlHwBJE6N0d9Qo7c8o7Qukvz9uHpslxkFrlpg2Be2apitQs1Han1HaF0h8f1pzTmtm5bQp05pZCY0HraTFkrblA8FdPfMn2kfS85Iek7RF0kRe1nPguzaStFbSXkmPF8qSHbivz/7cIGlX/m+0RdKSwrJr8v3ZJulzzdS6vEaDVtIhZD/juxA4FVieDxqXok9FxMLCpYR+A9+10R3A4q6ylAfuu4MD9wfg5vzfaGFErAPIj7dlwGn5Z76ZH5et1XSmPQfYHhHPRsSbwD3A0obrVJelwJ356zuBLzRYl2lFxCPAL7uK+9V/KXBXZDYBR3dGMGmLPvvTz1Lgnoh4IyKeA7aTHZet1XTQjsogcAH8WNLmfOwr6D/wXSpGceC+1XmTfm3hdCW5/Wk6aEfFeRFxJlnT8QpJ5xcXRtZFn2w3fer1z90GfARYCOwGbmy2OoNrOmhLDQLXdhGxK3/eC9xP1rzqN/BdKioN3Nc2EbEnIt6JiHeBb7O/CZzc/jQdtI8CCySdJOlwsg6BBxuu06xIOlLSUZ3XwAXA4/Qf+C4VIzVwX9d590Vk/0aQ7c8ySUdIOomsg+1nB7t+szLbGQbqfpANEvc02UBw1zZdnwHqfzLwX/njic4+0GfguzY+gLvJmoxvkZ3TrexXfwYYuK8l+/OdvL5byQJ1bmH9a/P92QZc2HT9Z3r4jiizxDTdPDazWXLQmiXGQWuWGAetWWIctGaJcdCaJcZBa5YYB61ZYv4fXk53eopJXx8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[-1][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False},\n",
       "       {'ale.lives': 3, 'lives': 3, 'terminal': False, 'lost_live': False}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Level=0 Room=1 Objects=0 x=159.4 y=29.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
